spark {
    app-name = "spark_application_name_1"
    master = "local[*]"
    speculation="false"
    serializer="org.apache.spark.serializer.KryoSerializer"
    sql {
        sources.commitProtocolClass="org.apache.spark.sql.execution.datasources.SQLEmrOptimizedCommitProtocol"
        hive.convertMetastoreParquet="true"
        parquet {
            fs.optimized.committer.optimization-enabled="true"
            output.committer.class="com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter"
        }
    }
    hadoop {
        mapreduce.fileoutputcommitter.algorithm.version = "2"
        fs.s3a {
            multiobjectdelete.enable="false"
            fast.upload="true"
        }
    }
}
