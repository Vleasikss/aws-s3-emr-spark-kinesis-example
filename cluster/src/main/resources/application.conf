spark {
    app-name = "spark_application_name"
    master = "local[*]"
    speculation="false"
    serializer="org.apache.spark.serializer.KryoSerializer"
    sql {
        sources.commitProtocolClass="org.apache.spark.sql.execution.datasources.SQLEmrOptimizedCommitProtocol"
        hive.convertMetastoreParquet="true"
        parquet {
            fs.optimized.committer.optimization-enabled="true"
            output.committer.class="com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter"
        }
    }
    hadoop {
        mapreduce.fileoutputcommitter.algorithm.version = "2"
        mapreduce.outputcommitter.factory.scheme.s3a="org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory"
        fs.s3a {
            multiobjectdelete.enable="false"
            committer.name=partitioned
            committer.staging.conflict-mode=replace
            fast.upload="true"
        }
    }
}
